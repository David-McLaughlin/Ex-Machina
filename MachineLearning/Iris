%python
###########################################################################################################################
# This is the IRIS Machine learning project with extensive comments developers who are new to machine learning and python #
# I am not the authore of the code base just of the comments - some small code changes were made to access the dataset    #
# Import lybraries and version                                                                                            #
#################################################################################################################################################
################################################### --- LIBRARY DEFINITIONS --- #################################################################
#################################################################################################################################################
# scipy
# SciPy is a scientific computation library that uses NumPy underneath. SciPy stands for Scientific Python.
# It provides more utility functions for optimization, stats and signal #processing. Like NumPy, SciPy is open source so we can use it freely.
#################################################################################################################################################
# numpy
# NumPy is a Python library used for working with arrays. It also has functions for working in domain of linear algebra, fourier transform, and matrices. 
# NumPy was created in 2005 by Travis Oliphant. It is an open source project and you can use it freely.
#################################################################################################################################################
# matplotlib
# Matplotlib is a cross-platform, data visualization and graphical plotting library for Python and its numerical extension NumPy.
#################################################################################################################################################
# pandas
# pandas is a software library written for the Python programming language for data manipulation and analysis. 
# In particular, it offers data structures and operations for manipulating numerical tables and time series
#################################################################################################################################################
# sklearn
# What is the sklearn in Python?
# Scikit-learn is a free machine learning library for Python. It features various algorithms like support vector machine, random forests, 
# and k-neighbours, and it also supports Python numerical and scientific libraries like NumPy and SciPy 
#################################################################################################################################################
import sys
print('Python: {}'.format(sys.version))
import scipy
print('scipy: {}'.format(scipy.__version__))
import numpy
print('numpy: {}'.format(numpy.__version__))
import matplotlib
print('matplotlib: {}'.format(matplotlib.__version__))
import pandas
print('pandas: {}'.format(pandas.__version__))
# scikit-learn
import sklearn
print('sklearn: {}'.format(sklearn.__version__))


##################
# Load libraries #
##################
import pandas
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn import model_selection
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

########################################
# list tables available in our Hive    #
# The Starter End Point must be active #
########################################
dbutils.fs.ls("dbfs:/user/hive/warehouse")

########################################
# Load Data and assign column headings #
########################################
print(' -----------------------------------------------------------------------------------------------------')
print(' --------------------------------------------  Load Data -------------------------------------------- ')
print(' -----------------------------------------------------------------------------------------------------')
dataset = spark.read.load("dbfs:/user/hive/warehouse/iris").toPandas()
dataset.columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
#####################
# Print our DataSet #
#####################
display(dataset)

      ################# ONLY REQUIRED FOR LOCAL EXECUTION ########################
      # *** IF YOU ARE NOT USING Databricks and running local use this code **** #
      # *** you must load the iris.csv into the directory specified by you  **** #
      # *** in the URL - google Iris this is a common AI project            *****#
      ################# READ ME --- READ ME --- READ ME --- ######################
      # url = "C:\SOMEDIR\ANOTHERDIR\iris.csv"
      # names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']
      # dataset = pandas.read_csv(url, names=names)


##################################################
# display shape data the number of rows, columns #
##################################################
print(' ----------------------------------------------------------------------------------------')
print(' -------------------------------------------- Print Shape Data (Rows/Col)')
print(' ----------------------------------------------------------------------------------------')
print(dataset.shape)
#################################################
# print the 10 first rows with the head command #
#################################################
print(' ----------------------------------------------------------------------------------------')
print(' -------------------------------------------- Print Head(10) - Data ')
print(' ----------------------------------------------------------------------------------------')
print(dataset.head(10))
#################################################
# print the 10 first rows with the head command #
#################################################
print(' ----------------------------------------------------------------------------------------')
print(' -------------------------------------------- Print Describe - Data ')
print(' ----------------------------------------------------------------------------------------')
print(dataset.describe())
